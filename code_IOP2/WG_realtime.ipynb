{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and plot near-real-time Wave Glider data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first cut by Tom, 10/18/2021  \n",
    "Updated for IOP1, 10/9/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import cftime\n",
    "import requests\n",
    "import cartopy.crs as ccrs                   # import projections\n",
    "import cartopy\n",
    "import gsw\n",
    "import functions  # requires functions.py from this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%matplotlib qt5\n",
    "plt.rcParams['figure.figsize'] = (7,4)\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['savefig.dpi'] = 400\n",
    "plt.close('all')\n",
    "\n",
    "__figdir__ = '../plots/' \n",
    "savefig_args = {'bbox_inches':'tight', 'pad_inches':0.2}\n",
    "plotfiletype='png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig = True\n",
    "zoom = True\n",
    "if zoom:\n",
    "    xmin, xmax = (-127,-121)\n",
    "    ymin, ymax = (36.25,38.5)\n",
    "    levels = np.linspace(14,17,21)-2.5\n",
    "else:\n",
    "    xmin, xmax = (-127,-121)\n",
    "    ymin, ymax = (35, 41)\n",
    "    levels = np.linspace(13,18,11)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Payload 2 Table 1 has met, ctd variables  \n",
    "Payload 2 Table 2 has RDI variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of WGs\n",
    "input_list = ['WHOI22','WHOI32','WHOI43','STOKES', 'PLANCK', 'KELVIN', 'CARSON']\n",
    "url_prefix = 'http://smode.whoi.edu:8080/thredds/dodsC/IOP2_2023/waveglider/'\n",
    "tab1_postfix = '_21.nc'#PLD2_TAB1\n",
    "tab2_postfix = '_22.nc' #PLD2_TAB2\n",
    "position_postfix = '_23.nc' # position??\n",
    "WG_list = ['WHOI22','WHOI32','WHOI43','STOKES', 'PLANCK', 'KELVIN', 'CARSON']\n",
    "outpath='../data/raw/WG_NRT_IOP2/'\n",
    "\n",
    "#http://smode.whoi.edu:8080/thredds/dodsC/IOP2_2023/waveglider/KELVIN_23.nc.html\n",
    "#http://smode.whoi.edu:8080/thredds/fileServer/IOP2_2023/waveglider/KELVIN_23.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://smode.whoi.edu:8080/thredds/dodsC/IOP2_2023/waveglider/WHOI22_23.nc\n",
      "http://smode.whoi.edu:8080/thredds/dodsC/IOP2_2023/waveglider/WHOI32_23.nc\n",
      "http://smode.whoi.edu:8080/thredds/dodsC/IOP2_2023/waveglider/WHOI43_23.nc\n",
      "http://smode.whoi.edu:8080/thredds/dodsC/IOP2_2023/waveglider/STOKES_23.nc\n",
      "http://smode.whoi.edu:8080/thredds/dodsC/IOP2_2023/waveglider/PLANCK_23.nc\n",
      "http://smode.whoi.edu:8080/thredds/dodsC/IOP2_2023/waveglider/KELVIN_23.nc\n",
      "http://smode.whoi.edu:8080/thredds/dodsC/IOP2_2023/waveglider/CARSON_23.nc\n"
     ]
    }
   ],
   "source": [
    "# For some reason, reading the files over the internet directly is not working well\n",
    "# Download instead\n",
    "\n",
    "n=0\n",
    "file_list1 = []\n",
    "file_list2 = []\n",
    "file_list3 = []\n",
    "for WG in WG_list:\n",
    "    input_WG=input_list[n]\n",
    "    outfile1 = outpath+input_WG+tab1_postfix\n",
    "    outfile2 = outpath+input_WG+tab2_postfix\n",
    "    outfile3 = outpath+input_WG+position_postfix\n",
    "    # Read and save table 1 files\n",
    "    url1 = url_prefix+input_WG+tab1_postfix\n",
    "    file_data = requests.get(url1).content\n",
    "    # create the file in write binary mode, because the data we get from net is in binary\n",
    "    with open(outfile1, \"wb\") as file:\n",
    "        file.write(file_data)\n",
    "    # Read and save table 2 files\n",
    "    url2 = url_prefix+input_WG+tab2_postfix\n",
    "    file_data = requests.get(url2).content\n",
    "    # create the file in write binary mode, because the data we get from net is in binary\n",
    "    with open(outfile2, \"wb\") as file:\n",
    "        file.write(file_data)\n",
    "    # Read and save position files\n",
    "    url3 = url_prefix+input_WG+position_postfix\n",
    "    file_data = requests.get(url3).content\n",
    "    # create the file in write binary mode, because the data we get from net is in binary\n",
    "    with open(outfile3, \"wb\") as file:\n",
    "        file.write(file_data)\n",
    "    n=n+1\n",
    "    print(url3)\n",
    "    file_list1.append(outfile1)\n",
    "    file_list2.append(outfile2)\n",
    "    file_list3.append(outfile3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/raw/WG_NRT_IOP2/WHOI22_22.nc',\n",
       " '../data/raw/WG_NRT_IOP2/WHOI32_22.nc',\n",
       " '../data/raw/WG_NRT_IOP2/WHOI43_22.nc',\n",
       " '../data/raw/WG_NRT_IOP2/STOKES_22.nc',\n",
       " '../data/raw/WG_NRT_IOP2/PLANCK_22.nc',\n",
       " '../data/raw/WG_NRT_IOP2/KELVIN_22.nc',\n",
       " '../data/raw/WG_NRT_IOP2/CARSON_22.nc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ds_time(ds):\n",
    "    '''\n",
    "    Drop nonunique values in realtime data files and sort time.\n",
    "    \n",
    "    Input: ds, xarray dataset\n",
    "    Output: ds, xarray dataset\n",
    "    '''\n",
    "    t, ind = np.unique(ds.time, return_index=True)\n",
    "    ds2 = ds.isel(time=ind,drop=True)\n",
    "    return ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'pydap']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttp://xarray.pydata.org/en/stable/getting-started-guide/installing.html\nhttp://xarray.pydata.org/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29224/95170680.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfile3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_list3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvarstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'met_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mWG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mds_met_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvarstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfix_ds_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_met_temp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Drop nonunique values and sort time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvarstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adcp_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mWG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, backend_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguess_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/xarray/backends/plugins.py\u001b[0m in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    150\u001b[0m         )\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'pydap']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttp://xarray.pydata.org/en/stable/getting-started-guide/installing.html\nhttp://xarray.pydata.org/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "# Read in files (Payload 2 Tables 1 and 2; position) from all WG\n",
    "n=0\n",
    "for WG in WG_list:\n",
    "    input_WG=input_list[n]\n",
    "    file1 = file_list1[n]\n",
    "    file2 = file_list2[n]\n",
    "    file3 = file_list3[n]\n",
    "    varstr = 'met_'+WG\n",
    "    ds_met_temp=xr.open_dataset(file1,decode_times=True)\n",
    "    locals()[varstr]=fix_ds_time(ds_met_temp) #Drop nonunique values and sort time\n",
    "    varstr = 'adcp_'+WG\n",
    "    !ncrename -v z,z_matrix $file2 #renaming variable z to prevent dimension/variable name conflict in xarray, requires nco in linux\n",
    "    ds_adcp_temp=xr.open_dataset(file2,decode_times=True)\n",
    "    locals()[varstr]=fix_ds_time(ds_adcp_temp) #Drop nonunique values and sort time\n",
    "    varstr = 'pos_'+WG\n",
    "    ds_pos_temp=xr.open_dataset(file3,decode_times=True)\n",
    "    locals()[varstr]=fix_ds_time(ds_pos_temp) #Drop nonunique values and sort time\n",
    "    n=n+1\n",
    "    print(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('met_'+WG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write WHOI22 met record to file\n",
    "# met_WHOI22.to_netcdf('../data/raw/WG_NRT/WHOI22_met.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we can access these in a loop using syntax like:\n",
    "# eval('adcp_'+WG_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval('met_'+WG_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compute density from T and cond\n",
    "p = 1\n",
    "for WG in WG_list:\n",
    "    ds = eval('met_'+WG)\n",
    "    ds['uctd_psu_Avg']=gsw.conversions.SP_from_C(10*ds.uctd_cond_Avg, ds.uctd_temp_Avg, p)\n",
    "    SA = gsw.conversions.SA_from_SP(ds.uctd_psu_Avg, 1,ds.longitude_1hz_Avg, ds.latitude_1hz_Avg)\n",
    "    CT = gsw.conversions.CT_from_t(SA, ds.uctd_temp_Avg, p)\n",
    "    ds['uctd_sigma0_Avg'] = gsw.density.sigma0(SA, CT)\n",
    "    varstr = 'met_'+WG\n",
    "    locals()[varstr]= ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_WG_SST(V,n,tmin):\n",
    "    extent = [xmin, xmax, ymin, ymax]\n",
    "    ds = eval('met_'+WG_list[n])\n",
    "    ds2 = ds.where(ds.time>tmin)\n",
    "    sst = ds2.uctd_temp_Avg.values.astype(np.ndarray)\n",
    "    ax.set_title('WG SST',size = 10.)\n",
    "    plt.scatter(ds2.longitude_1hz_Avg, ds2.latitude_1hz_Avg,s=5,c=sst, cmap=plt.get_cmap('turbo'),vmin=V[0],vmax=V[1],transform=ccrs.PlateCarree())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_WG_sigma0(V,n,tmin):\n",
    "    extent = [xmin, xmax, ymin, ymax]\n",
    "    ds = eval('met_'+WG_list[n])\n",
    "    ds2 = ds.where(ds.time>tmin)\n",
    "    rho = ds2.uctd_sigma0_Avg.values.astype(np.ndarray)\n",
    "    ax.set_title('$\\sigma_0$',size = 10.)\n",
    "    plt.scatter(ds2.longitude_1hz_Avg, ds2.latitude_1hz_Avg,s=5,c=rho, cmap=plt.get_cmap('turbo'),vmin=V[0],vmax=V[1],transform=ccrs.PlateCarree())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "V = [14,18]\n",
    "Vrho = [23,24.5]\n",
    "tmin = np.datetime64('2022-10-10T00:00:00')\n",
    "n = 0\n",
    "extent = [xmin, xmax, ymin, ymax]\n",
    "ax = plt.axes(projection = ccrs.PlateCarree(central_longitude=200))  # Orthographic\n",
    "ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "for n in range(8):\n",
    "        #plot_WG_time(n)\n",
    "        #plot_WG_SST(V,n,tmin)\n",
    "        plot_WG_sigma0(Vrho,n,tmin)\n",
    "\n",
    "\n",
    "plt.colorbar(location = 'bottom')\n",
    "ax.coastlines()\n",
    "ax.add_feature(cartopy.feature.LAND, zorder=3, facecolor=[.6,.6,.6], edgecolor='black')\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, alpha=0.5, linestyle='--')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "functions.plot_ops_area(ax,transform=ccrs.PlateCarree(),color='k');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_WG_sigma0_lat(n,tmin):\n",
    "    ds = eval('met_'+WG_list[n])\n",
    "    ds2 = ds.where(ds.time>tmin)\n",
    "    rho = ds2.uctd_sigma0_Avg.values.astype(np.ndarray)\n",
    "    ax.set_title('$\\sigma_0$',size = 10.)\n",
    "    plt.scatter(rho,ds2.latitude_1hz_Avg,s=5,c=(ds2.time-tmin)*10**-9/(60*60*24), cmap=plt.get_cmap('turbo'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "V = [14,18]\n",
    "Vrho = [23,24.5]\n",
    "tmin = np.datetime64('2022-10-09T00:00:00')\n",
    "for n in range(8):\n",
    "        #plot_WG_time(n)\n",
    "        #plot_WG_SST(V,n,tmin)\n",
    "        plot_WG_sigma0_lat(n,tmin)\n",
    "\n",
    "plt.colorbar(location = 'right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's look at RDI files (Table 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval('adcp_'+WG_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval('met_'+WG_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval('pos_'+WG_list[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we have 15 minute files from the ADCP and 5 minute from the position files.  Interpolate the position files to the ADCP times.  That should be easy using xarray interp package, following:  \n",
    "https://docs.xarray.dev/en/stable/user-guide/interpolation.htmlhttps://docs.xarray.dev/en/stable/user-guide/interpolation.html  \n",
    "\n",
    "```\n",
    "new_lon = -126.1\n",
    "new_lat = 37.1\n",
    "new_time = ds.time[-3]\n",
    "dsi = ds.interp(time=new_time,latitude=new_lat, longitude=new_lon)\n",
    "```\n",
    "\n",
    "```\n",
    "new_time = ds_adcp.time\n",
    "ds_pos_i = ds_pos.interp(time=new_time)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_adcp = eval('adcp_'+WG_list[7])\n",
    "# ds_pos = eval('pos_'+WG_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_time = np.unique(ds_adcp.time)\n",
    "# ds_pos_i = ds_pos.interp(time=new_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('adcp_'+WG_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate each WG's position to ADCP time and add to ADCP file\n",
    "for WG in WG_list:\n",
    "    ds_adcp = eval('adcp_'+WG)\n",
    "    ds_pos = eval('pos_'+WG)\n",
    "    ds_pos_i = ds_pos.interp(time=ds_adcp.time)\n",
    "    ds_adcp['Longitude']=ds_pos_i.Longitude\n",
    "    ds_adcp['Latitude']=ds_pos_i.Latitude\n",
    "    varstr = 'adcp_'+WG\n",
    "    locals()[varstr]= ds_adcp\n",
    "    del ds_adcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('adcp_'+WG_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = np.datetime64('2022-10-10T00:00:00')\n",
    "tmax = np.datetime64('now')\n",
    "vmin = -.50 \n",
    "vmax = .50\n",
    "levels=np.arange(vmin,vmax,.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.set_cmap(cmap=plt.get_cmap('turbo'))\n",
    "n = 0\n",
    "ax1 = plt.subplot(8,1,8)\n",
    "ax1.set_xlim(tmin,tmax)\n",
    "zmax=-60\n",
    "for WG in WG_list:\n",
    "    n=n+1\n",
    "    ds = eval('adcp_'+WG)\n",
    "    ax = plt.subplot(8,1,n,sharex=ax1)\n",
    "    im = plt.pcolor(ds.time.values,ds.z_matrix,ds.current_east,vmin=vmin,vmax=vmax)\n",
    "    # plt.contourf(ds.time.values,ds.z_matrix[:,1],ds.current_east,levels)\n",
    "    plt.ylim(zmax, 0)\n",
    "    plt.text(tmin,zmax+5,WG)\n",
    "    if n==1: plt.title('East vel')\n",
    "fig=plt.gcf()\n",
    "fig.autofmt_xdate()\n",
    "fig.subplots_adjust(right=0.85)\n",
    "cbar_ax = fig.add_axes([0.875, 0.1, 0.025, 0.8])\n",
    "fig.colorbar(im, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.set_cmap(cmap=plt.get_cmap('turbo'))\n",
    "n = 0\n",
    "ax1 = plt.subplot(8,1,8)\n",
    "ax1.set_xlim(tmin,tmax)\n",
    "for WG in WG_list:\n",
    "    n=n+1\n",
    "    ds = eval('adcp_'+WG)\n",
    "    ax = plt.subplot(8,1,n,sharex=ax1)\n",
    "    im = plt.pcolor(ds.time.values,ds.z_matrix,ds.current_north,vmin=vmin,vmax=vmax)\n",
    "    # plt.contourf(ds.time.values,ds.z_matrix[:,1],ds.current_east,levels)\n",
    "    plt.ylim(-60, 0)\n",
    "    plt.text(tmin,zmax+5,WG)\n",
    "    if n==1: plt.title('North vel')\n",
    "fig=plt.gcf()\n",
    "fig.autofmt_xdate()\n",
    "fig.subplots_adjust(right=0.85)\n",
    "cbar_ax = fig.add_axes([0.875, 0.1, 0.025, 0.8])\n",
    "fig.colorbar(im, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that's very cool!  I have all the files cleaned up and have added the lat/lon.  Le't get ready to try finding the ones in the tringle and doing the LS fit.  Maybe a good intermediate step is to plot the vectors on a map.  Or, maybe better would be to do the same plots as the last two above, but showing only the data from the triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon0 = -124.66\n",
    "lat0 = 36.96\n",
    "tol = .023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.set_cmap(cmap=plt.get_cmap('turbo'))\n",
    "n = 0\n",
    "ax1 = plt.subplot(8,1,8)\n",
    "ax1.set_xlim(tmin,tmax)\n",
    "for WG in WG_list:\n",
    "    n=n+1\n",
    "    ds = eval('adcp_'+WG)\n",
    "    ds = ds.where(np.logical_and(np.abs(ds.Latitude.values-lat0)<tol, np.abs(ds.Longitude.values-lon0)<tol))\n",
    "    ax = plt.subplot(8,1,n,sharex=ax1)\n",
    "    im = plt.pcolor(ds.time.values,ds.z_matrix,ds.current_north,vmin=vmin,vmax=vmax)\n",
    "    # plt.contourf(ds.time.values,ds.z_matrix[:,1],ds.current_east,levels)\n",
    "    plt.ylim(-60, 0)\n",
    "    plt.text(tmin,zmax+5,WG)\n",
    "    if n==1: plt.title('North vel')\n",
    "fig=plt.gcf()\n",
    "fig.autofmt_xdate()\n",
    "fig.subplots_adjust(right=0.85)\n",
    "cbar_ax = fig.add_axes([0.875, 0.1, 0.025, 0.8])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "if savefig:\n",
    "    plt.savefig(__figdir__+'WG_triangle_north_vel'+'.'+plotfiletype,**savefig_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.set_cmap(cmap=plt.get_cmap('turbo'))\n",
    "n = 0\n",
    "ax1 = plt.subplot(8,1,8)\n",
    "ax1.set_xlim(tmin,tmax)\n",
    "zmax=-60\n",
    "for WG in WG_list:\n",
    "    n=n+1\n",
    "    ds = eval('adcp_'+WG)\n",
    "    ds = ds.where(np.logical_and(np.abs(ds.Latitude.values-lat0)<tol, np.abs(ds.Longitude.values-lon0)<tol))\n",
    "    ax = plt.subplot(8,1,n,sharex=ax1)\n",
    "    im = plt.pcolor(ds.time.values,ds.z_matrix,ds.current_east,vmin=vmin,vmax=vmax)\n",
    "    # plt.contourf(ds.time.values,ds.z_matrix[:,1],ds.current_east,levels)\n",
    "    plt.ylim(zmax, 0)\n",
    "    plt.text(tmin,zmax+5,WG)\n",
    "    if n==1: plt.title('East vel')\n",
    "fig=plt.gcf()\n",
    "fig.autofmt_xdate()\n",
    "fig.subplots_adjust(right=0.85)\n",
    "cbar_ax = fig.add_axes([0.875, 0.1, 0.025, 0.8])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "if savefig:\n",
    "    plt.savefig(__figdir__+'WG_triangle_east_vel'+'.'+plotfiletype,**savefig_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, WHOI32 has been in the first triangle for about the whole time (since the 12th).  Let's plot a time series of that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "WG = 'WHOI32'\n",
    "ds = eval('adcp_'+WG)\n",
    "ds = ds.where(np.logical_and(np.abs(ds.Latitude.values-lat0)<tol, np.abs(ds.Longitude.values-lon0)<tol))\n",
    "im = plt.pcolor(ds.time.values,ds.z_matrix,ds.current_east,vmin=vmin,vmax=vmax)\n",
    "# plt.contourf(ds.time.values,ds.z_matrix[:,1],ds.current_east,levels)\n",
    "plt.ylim(zmax, 0)\n",
    "plt.text(tmin,zmax+5,WG)\n",
    "plt.title('East vel for ' + WG + ' when in triangle')\n",
    "fig.autofmt_xdate()\n",
    "fig.subplots_adjust(right=0.85)\n",
    "cbar_ax = fig.add_axes([0.875, 0.1, 0.025, 0.8])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "ax.set_xlim(tmin,tmax)\n",
    "if 0: #savefig:\n",
    "    plt.savefig(__figdir__+'WHOI32_triangle_east_vel'+'.'+plotfiletype,**savefig_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "WG = 'WHOI32'\n",
    "ds = eval('adcp_'+WG)\n",
    "ds = ds.where(np.logical_and(np.abs(ds.Latitude.values-lat0)<tol, np.abs(ds.Longitude.values-lon0)<tol))\n",
    "ind=np.flatnonzero(np.isnan(ds.z_matrix[1][:])==False)\n",
    "z = ds.z_matrix[:,ind[0]]\n",
    "z0 = -15\n",
    "zind = np.flatnonzero(np.abs(z-z0)<1)\n",
    "plt.plot(ds.time.values,np.squeeze(ds.current_east[zind,]))\n",
    "plt.plot(ds.time.values,np.squeeze(ds.current_north[zind,]))\n",
    "plt.legend(['U','V'])\n",
    "# plt.contourf(ds.time.values,ds.z_matrix[:,1],ds.current_east,levels)\n",
    "plt.title(WG+ ' east vel')\n",
    "plt.ylabel('[m/s]')\n",
    "fig.autofmt_xdate()\n",
    "ax.set_xlim(tmin,tmax)\n",
    "if savefig:\n",
    "    plt.savefig(__figdir__+'WHOI32_triangle_time_series'+'.'+plotfiletype,**savefig_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9*60*60*.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the tapered and weighted least-squares solution (Equation 1.125 in the course notes),\n",
    "\\begin{equation}\n",
    "  \\tilde{\\mathbf{x}}=\\left(\\mathbf{E}^T\\mathbf{W}^{-1}\\mathbf{E}+\\mathbf{S}^{-1}\\right)^{-1}\\left(\\mathbf{E}^T\\mathbf{W}^{-1}\\mathbf{y}+\\mathbf{S}^{-1}\\mathbf{x_0}\\right).\n",
    " \\label{TW_LS}\n",
    "\\end{equation}\n",
    "Recall that $\\mathbf{W}^{-1}$ is a ''weight matrix'', $\\mathbf{S}^{-1}$ is a ''taper matrix'' (which can be thought of as another weight matrix, as we shall see soon), and $\\mathbf{x_0}$ is the first guess solution.  Just to simplify the notation and discussion a little bit, we will assume that $\\mathbf{x_0}=0$, which would be the case if we know or think that the expectation value $<\\mathbf{x}>=0$.  In that case\n",
    "\\begin{equation}\n",
    "  \\tilde{\\mathbf{x}}=\\left(\\mathbf{E}^T\\mathbf{W}^{-1}\\mathbf{E}+\\mathbf{S}^{-1}\\right)^{-1}\\mathbf{E}^T\\mathbf{W}^{-1}\\mathbf{y}.\n",
    " \\label{TW_LS2}\n",
    "\\end{equation}\n",
    "\n",
    "Again assuming $\\mathbf{x_0}=0$, the cost function that led to Equation \\ref{TW_LS2} was (Equation 1.193 in the notes):\n",
    "\\begin{equation}\n",
    "  J=\\mathbf{n}^T \\mathbf{W}^{-1}\\mathbf{n}+\\mathbf{x}^T\\mathbf{S}^{-1}\\mathbf{x}.\n",
    " \\label{J_TW_LS2}\n",
    "\\end{equation}\n",
    "\n",
    "Like most complicated equations, we can get a better feel for what the equation means by considering some special cases.  A common special case to consider in matrix problems is one where some matrices are diagonal and square, because these matrices can easily be inverted.  If $\\mathbf{W}=a \\mathbf{I}$, then $\\mathbf{W}^{-1}=\\frac{1}{a} \\mathbf{I}$. So, let's try letting $\\mathbf{W}^{-1}=\\frac{1}{\\sigma_n^2} \\mathbf{I}$ and letting $\\mathbf{S}^{-1}=\\frac{1}{\\Delta_x^2} \\mathbf{I}$.  Then, the cost function in Equation \\ref{J_TW_LS2} becomes\n",
    "\\begin{equation}\n",
    "  J=\\frac{1}{\\sigma_n^2}\\mathbf{n}^T \\mathbf{n}+\\frac{1}{\\Delta_x^2}\\mathbf{x}^T \\mathbf{x},\n",
    " \\label{J_TW_LS2_simple}\n",
    "\\end{equation}\n",
    "and Equation \\ref{TW_LS2} becomes:\n",
    "\\begin{equation}\n",
    "  \\tilde{\\mathbf{x}}=\\left(\\frac{1}{\\sigma_n^2}\\mathbf{E}^T \\mathbf{E}+\\frac{1}{\\Delta_x^2}\\mathbf{I}\\right)^{-1}\\frac{1}{\\sigma_n^2}\\mathbf{E}^T\\ \\mathbf{y},\n",
    "  \\nonumber\n",
    "\\end{equation}\n",
    "or,\n",
    "\\begin{equation}\n",
    "  \\tilde{\\mathbf{x}}=\\left(\\mathbf{E}^T\\mathbf{E}+\\frac{\\sigma_n^2}{\\Delta_x^2}\\mathbf{I}\\right)^{-1}\\mathbf{E}^T \\mathbf{y}.\n",
    " \\label{TW_LS2_simple}\n",
    "\\end{equation}\n",
    "If $\\sigma_n^2$ is the expected noise variance and $\\Delta_x^2$ is the expected solution variance, then we can interpret Equation \\ref{J_TW_LS2_simple} as a cost function where we equally penalize (in a normalized sense) the estimated noise variance and the estimated solution variance.  We are simultaneously minimizing the model-data misfit and the solution variance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The tapering parameter $\\sigma_n^2/\\Delta_x^2$ can be considered to be an inverse signal-to-noise ratio (SNR), expressing our expectation about the relative variance of the measurement noise and the solution.  In the limit that the tapering parameter is very small (meaning the SNR is high), Equation \\ref{TW_LS2_simple} is just the ordinary least squares solution.  If the tapering parameter is small, the tapered least squares solution could also be viewed as a mere computational trick-- by adding a small value to the diagonal of $\\mathbf{E}^T\\mathbf{E}$, we have guaranteed that the inverse $\\left(\\mathbf{E}^T\\mathbf{E}+\\frac{\\sigma_n^2}{\\Delta_x^2}\\mathbf{I}\\right)^{-1}$ exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
